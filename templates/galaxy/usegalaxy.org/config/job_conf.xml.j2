<?xml version="1.0"?>
<!--
    This file is maintained by Ansible - CHANGES WILL BE OVERWRITTEN
-->
<job_conf>
    <plugins workers="8">
        <!-- This will work after 9/22
        <plugin id="dynamic" type="runner">
            <!- - These live in the virtualenv - ->
            <param id="rules_module">usegalaxy.jobs.rules</param>
        </plugin>
        -->
        <plugin id="slurm" type="runner" load="galaxy.jobs.runners.slurm:SlurmJobRunner"/>
    </plugins>
    <handlers default="handlers">
        <handler id="main_w1_handler0" tags="handlers"/>
        <handler id="main_w1_handler1" tags="handlers"/>
        <handler id="main_w2_handler0" tags="handlers"/>
        <handler id="main_w2_handler1" tags="handlers"/>
        <!-- a handler for old jobs, to inmprove startup times of other handlers -->
        <handler id="main_w1_handler2"/>
        <!-- a handler for multi jobs to avoid the concurrency limit race condition -->
        <handler id="main_w2_handler2"/>
    </handlers>
    <destinations default="reserved_single">
        <!-- dynamic methods for selecting reserved node -->
        <destination id="reserved_single" runner="dynamic">
            <param id="type">python</param>
            <param id="function">reserved_single</param>
        </destination>
        <destination id="reserved_multi" runner="dynamic">
            <param id="type">python</param>
            <param id="function">reserved_multi</param>
        </destination>

        <!-- roundup destinations -->
        <destination id="roundup_single" runner="slurm">
            <param id="nativeSpecification">--time=48:00:00 --nodes=1 --ntasks=1 --partition=single --constraint=general</param>
        </destination>
        <destination id="roundup_multi" runner="slurm">
            <param id="nativeSpecification">--time=48:00:00 --nodes=1 --ntasks=8 --partition=multi</param>
        </destination>
        <destination id="roundup_trackster_multi" runner="slurm">
            <param id="nativeSpecification">--time=00:05:00 --nodes=1 --ntasks=8 --partition=single --constraint=general</param>
        </destination>

        <!-- old roundup names, remove after all jobs have disappeared from here -->
        <destination id="slurm_single" runner="slurm">
            <param id="nativeSpecification">--time=48:00:00 --nodes=1 --ntasks=1 --partition=single --constraint=general</param>
        </destination>
        <destination id="slurm_multi" runner="slurm">
            <param id="nativeSpecification">--time=48:00:00 --nodes=1 --ntasks=8 --partition=multi</param>
        </destination>
        <destination id="slurm_trackster_multi" runner="slurm">
            <param id="nativeSpecification">--time=00:05:00 --nodes=1 --ntasks=8 --partition=single --constraint=general</param>
        </destination>
    </destinations>
    <tools>
        <tool id="bowtie2" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="bowtie_wrapper" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="bowtie_color_wrapper" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="bwa_wrapper" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="bwa_color_wrapper" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="lastz_wrapper_2" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="generate_coverage_report" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="quality_score_distribution" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="megablast_wrapper" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="cuffdiff" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="cufflinks" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="cuffmerge" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="tophat" destination="reserved_multi" handler="main_w2_handler2"/>
        <tool id="tophat2" destination="reserved_multi" handler="main_w2_handler2"/>
        <!-- trackster jobs -->
        <tool id="cufflinks" destination="slurm_trackster_multi">
            <param id="source">trackster</param>
        </tool>
        <!-- nagios checks -->
        <tool id="echo_main_w1_handler0" handler="main_w1_handler0"/>
        <tool id="echo_main_w1_handler1" handler="main_w1_handler1"/>
        <tool id="echo_main_w1_handler2" handler="main_w1_handler2"/>
        <tool id="echo_main_w2_handler0" handler="main_w2_handler0"/>
        <tool id="echo_main_w2_handler1" handler="main_w2_handler1"/>
        <tool id="echo_main_w2_handler2" handler="main_w2_handler2"/>
    </tools>
    <limits>
        <limit type="registered_user_concurrent_jobs">6</limit>
        <limit type="anonymous_user_concurrent_jobs">1</limit>
        <limit type="job_walltime">49:00:00</limit>
        <limit type="output_size">150G</limit>
        <!-- per-destination per-user limits -->
        <limit type="destination_user_concurrent_jobs" id="roundup_trackster_multi">1</limit>
        <limit type="destination_user_concurrent_jobs" id="roundup_multi">2</limit>
        <limit type="destination_user_concurrent_jobs" id="roundup_single">4</limit>
        <!-- remove after jobs have disappeared from old-named destinations -->
        <limit type="destination_user_concurrent_jobs" id="slurm_trackster_multi">1</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_multi">2</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_single">4</limit>
        <!-- per-destination total limits -->
    </limits>
</job_conf>
